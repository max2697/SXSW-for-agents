<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>How We Could Lose Control: Avoiding the Paths to Runaway AI | SXSW 2026</title>
  <meta name="description" content="Event detail page for How We Could Lose Control: Avoiding the Paths to Runaway AI.">
  <meta name="robots" content="index,follow,max-snippet:-1,max-image-preview:large,max-video-preview:-1">
  <link rel="canonical" href="https://sxsw.0fn.net/schedule/event/PP1162234.html">
  <meta property="og:type" content="website">
  <meta property="og:title" content="How We Could Lose Control: Avoiding the Paths to Runaway AI | SXSW 2026">
  <meta property="og:description" content="Event detail page for How We Could Lose Control: Avoiding the Paths to Runaway AI.">
  <meta property="og:url" content="https://sxsw.0fn.net/schedule/event/PP1162234.html">
  <meta property="og:image" content="https://sxsw.0fn.net/schedule/og-default.svg">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="How We Could Lose Control: Avoiding the Paths to Runaway AI | SXSW 2026">
  <meta name="twitter:description" content="Event detail page for How We Could Lose Control: Avoiding the Paths to Runaway AI.">
  <meta name="twitter:image" content="https://sxsw.0fn.net/schedule/og-default.svg">
  <link rel="stylesheet" href="/schedule/styles.css">
</head>
<body>
  <main><p class="breadcrumbs"><a href="/index.html">Home</a> / <a href="/schedule/index.html">Schedule</a> / <a href="/schedule/date/2026-03-13.html">Fri, Mar 13, 2026</a></p>
<section class="hero">
  <h1>How We Could Lose Control: Avoiding the Paths to Runaway AI</h1>
  <p class="meta mono">Event ID: PP1162234</p>
  <p class="meta">Fri, Mar 13, 2026 | 4:30 PM - 5:30 PM</p>
  <p class="meta">Venue: Salon AB (JW Marriott)</p>
  <p><a class="button" href="https://schedule.sxsw.com/2026/events/PP1162234" target="_blank" rel="noopener noreferrer">View on Official SXSW</a></p>
</section>
<section class="panel">
  <h2>Summary</h2>
  <p>When experts talk about AI risks, they often talk about the loss of human control – but what does that actually mean? And how could it happen? In this fireside chat, physicist Anthony Aguirre and tech ethicist Tristan Harris go beyond surface-level alarm to map out the real mechanisms that could lead humanity to be sidelined by its own creation. From opaque incentives and design choices to systemic misalignment and power concentration, they’ll unpack how humans could lose control over AI and what can still be done to prevent it.</p>
  <ul class="flat">
    <li><strong>Format:</strong> Fireside Chat</li>
    <li><strong>Category:</strong> Fireside Chat</li>
    <li><strong>Event Type:</strong> panel</li>
    <li><strong>Presented By:</strong> n/a</li>
  </ul>
</section>
<section class="panel"><h2>Contributors</h2><ul class="flat"><li>Tristan Harris</li><li>Anthony Aguirre</li></ul></section>
<section class="panel">
  <h2>Raw Event JSON</h2>
  <p class="small">Large nested arrays are compacted for page readability. Full payload remains in dataset files.</p>
  <details>
    <summary>Open JSON payload</summary>
    <pre>{
  &quot;id&quot;: &quot;PP1162234&quot;,
  &quot;track&quot;: &quot;Tech &amp; AI&quot;,
  &quot;focus_area&quot;: null,
  &quot;category&quot;: &quot;Fireside Chat&quot;,
  &quot;event_id&quot;: &quot;PP1162234&quot;,
  &quot;event_type&quot;: &quot;panel&quot;,
  &quot;format&quot;: &quot;Fireside Chat&quot;,
  &quot;genre&quot;: null,
  &quot;subgenre&quot;: null,
  &quot;name&quot;: &quot;How We Could Lose Control: Avoiding the Paths to Runaway AI&quot;,
  &quot;presented_by&quot;: null,
  &quot;publish_at&quot;: &quot;2025-11-03T16:30:00.000-06:00&quot;,
  &quot;reservable&quot;: true,
  &quot;reservable_id&quot;: &quot;PP1162234&quot;,
  &quot;reserved&quot;: false,
  &quot;date&quot;: &quot;2026-03-13&quot;,
  &quot;end_time&quot;: &quot;2026-03-13T12:30:00.000-05:00&quot;,
  &quot;start_time&quot;: &quot;2026-03-13T11:30:00.000-05:00&quot;,
  &quot;message&quot;: null,
  &quot;image&quot;: null,
  &quot;credentials&quot;: [
    {
      &quot;name&quot;: &quot;Platinum Badge&quot;,
      &quot;type&quot;: &quot;platinum&quot;
    },
    {
      &quot;name&quot;: &quot;Innovation Badge&quot;,
      &quot;type&quot;: &quot;innovation&quot;
    }
  ],
  &quot;contributors&quot;: [
    {
      &quot;id&quot;: 7721,
      &quot;company&quot;: &quot;Center For Humane Technology&quot;,
      &quot;credential_types&quot;: [
        &quot;innovation&quot;
      ],
      &quot;entity_id&quot;: 1935182,
      &quot;name&quot;: &quot;Tristan Harris&quot;,
      &quot;speaker_types&quot;: [],
      &quot;title&quot;: &quot;Co-founder&quot;,
      &quot;image&quot;: {
        &quot;alt_text&quot;: &quot;Tristan Harris&quot;,
        &quot;credit&quot;: null,
        &quot;url&quot;: &quot;https://images.sxsw.com/qq-52R_gFbyriiuQQFzEpEHa7oc=/0x454:4727x5181/600x600/images.sxsw.com/48/c14af337-6978-4757-ac01-9b6eb7f89e5d/pcid-508691&quot;
      },
      &quot;speaker_type&quot;: &quot;Speaker&quot;,
      &quot;details&quot;: &quot;Called “the closest thing Silicon Valley has to a conscience” by the Atlantic, Tristan Harris is a technology ethicist and co-founder of the Center for Humane Technology, a nonprofit dedicated to aligning technology with humanity’s best interest. Tristan gained international recognition when he was featured in the Emmy-winning Netflix documentary, The Social Dilemma. Since raising the alarm on the harms of social media, Tristan has emerged as a leading public educator on the harms of unregulated artificial intelligence. Named to the TIME100 AI list in 2023, Tristan is “a tech leader committed to ensuring that we get this generation of AI right, because we simply can’t afford to get it wrong.”    \n&quot;,
      &quot;links&quot;: {},
      &quot;type&quot;: &quot;person&quot;
    },
    {
      &quot;id&quot;: 44096,
      &quot;company&quot;: &quot;Future of Life Institute&quot;,
      &quot;credential_types&quot;: [
        &quot;innovation&quot;
      ],
      &quot;entity_id&quot;: 2194071,
      &quot;name&quot;: &quot;Anthony Aguirre&quot;,
      &quot;speaker_types&quot;: [],
      &quot;title&quot;: &quot;Executive Director&quot;,
      &quot;image&quot;: {
        &quot;alt_text&quot;: &quot;Anthony Aguirre&quot;,
        &quot;credit&quot;: null,
        &quot;url&quot;: &quot;https://images.sxsw.com/YDDqklFPbtNpMJX8ZYX_fqtge0A=/1254x332:3902x2980/600x600/images.sxsw.com/48/fa0ef89b-83e8-4904-a8af-955f77f7cfba/pcid-1259046&quot;
      },
      &quot;speaker_type&quot;: &quot;Speaker&quot;,
      &quot;details&quot;: &quot;Anthony is the Executive Director &amp; Secretary of the Board at the Future of Life Institute, and the Faggin Presidential Professor for the Physics of Information at UC Santa Cruz. He has done research in an array of topics in theoretical cosmology, gravitation, statistical mechanics, and other fields of physics. He also has strong interest in science outreach, and has appeared in numerous science documentaries. He is a creator of the science and technology prediction platform Metaculus.com, and is founder (with Max Tegmark) of the Foundational Questions Institute.&quot;,
      &quot;links&quot;: {},
      &quot;type&quot;: &quot;person&quot;
    }
  ],
  &quot;venue&quot;: {
    &quot;accessible&quot;: false,
    &quot;age_policy&quot;: null,
    &quot;floor&quot;: &quot;3&quot;,
    &quot;id&quot;: &quot;V1349&quot;,
    &quot;indoor_outdoor&quot;: null,
    &quot;name&quot;: &quot;Salon AB&quot;,
    &quot;parent_id&quot;: &quot;V0403&quot;,
    &quot;parent_venue_name&quot;: &quot;JW Marriott&quot;,
    &quot;venue_entry_info&quot;: null,
    &quot;formats&quot;: null,
    &quot;location&quot;: {
      &quot;address&quot;: &quot;110 E 2nd St.&quot;,
      &quot;lat_lon&quot;: [
        30.2645713,
        -97.743198
      ],
      &quot;city&quot;: &quot;Austin&quot;,
      &quot;postal_code&quot;: &quot;78701&quot;,
      &quot;state&quot;: &quot;TX&quot;,
      &quot;name&quot;: &quot;JW Marriott&quot;
    },
    &quot;root&quot;: {
      &quot;accessible&quot;: null,
      &quot;age_policy&quot;: null,
      &quot;floor&quot;: null,
      &quot;id&quot;: &quot;V0403&quot;,
      &quot;indoor_outdoor&quot;: null,
      &quot;name&quot;: &quot;JW Marriott&quot;,
      &quot;parent_id&quot;: null,
      &quot;parent_venue_name&quot;: null,
      &quot;venue_entry_info&quot;: null,
      &quot;formats&quot;: null
    },
    &quot;events&quot;: &quot;[omitted 5 venue events]&quot;
  },
  &quot;description&quot;: &quot;When experts talk about AI risks, they often talk about the loss of human control – but what does that actually mean? And how could it happen? In this fireside chat, physicist Anthony Aguirre and tech ethicist Tristan Harris go beyond surface-level alarm to map out the real mechanisms that could lead humanity to be sidelined by its own creation. From opaque incentives and design choices to systemic misalignment and power concentration, they’ll unpack how humans could lose control over AI and what can still be done to prevent it.&quot;,
  &quot;experience_level&quot;: &quot;Intermediate&quot;,
  &quot;accessibility&quot;: [],
  &quot;accessible_venue&quot;: false,
  &quot;add_bcl_url&quot;: false,
  &quot;add_slido&quot;: false,
  &quot;age_policy&quot;: null,
  &quot;american_sign_language&quot;: false,
  &quot;apple_url&quot;: null,
  &quot;audio_description&quot;: false,
  &quot;caption_url&quot;: null,
  &quot;closed_captioned&quot;: false,
  &quot;cpe_credit&quot;: false,
  &quot;has_subtitles&quot;: false,
  &quot;hash_tags&quot;: [],
  &quot;high_sensory_experience&quot;: false,
  &quot;live&quot;: false,
  &quot;long_description&quot;: &quot;When experts talk about AI risks, they often talk about the loss of human control – but what does that actually mean? And how could it happen? In this fireside chat, physicist Anthony Aguirre and tech ethicist Tristan Harris go beyond surface-level alarm to map out the real mechanisms that could lead humanity to be sidelined by its own creation. From opaque incentives and design choices to systemic misalignment and power concentration, they’ll unpack how humans could lose control over AI and what can still be done to prevent it.&quot;,
  &quot;meeting_url&quot;: null,
  &quot;meeting_url_live&quot;: false,
  &quot;mentorly_url&quot;: null,
  &quot;mobile_audio_url&quot;: null,
  &quot;open_captioned&quot;: false,
  &quot;playlist_tag&quot;: null,
  &quot;rebroadcast&quot;: false,
  &quot;recommended_ids&quot;: [],
  &quot;search_conversions&quot;: null,
  &quot;short_program&quot;: false,
  &quot;slido_url&quot;: null,
  &quot;sort&quot;: &quot;HOW WE COULD LOSE CONTROL: AVOIDING THE PATHS TO RUNAWAY AI&quot;,
  &quot;source&quot;: &quot;Official&quot;,
  &quot;squad_up_url&quot;: null,
  &quot;stream_embed&quot;: null,
  &quot;stream_id&quot;: null,
  &quot;stream_url&quot;: null,
  &quot;strobe_warning&quot;: false,
  &quot;subdiscipline&quot;: null,
  &quot;summit&quot;: null,
  &quot;summit_display_name&quot;: null,
  &quot;tags&quot;: [
    {
      &quot;id&quot;: 2114,
      &quot;name&quot;: &quot;AI&quot;,
      &quot;created_at&quot;: &quot;2020-01-17T14:51:44.091-06:00&quot;,
      &quot;updated_at&quot;: &quot;2026-02-18T02:42:15.008-06:00&quot;,
      &quot;sort&quot;: &quot;AI&quot;,
      &quot;alpha&quot;: &quot;A&quot;
    },
    {
      &quot;id&quot;: 1323,
      &quot;name&quot;: &quot;Ethics&quot;,
      &quot;created_at&quot;: &quot;2017-10-11T17:41:47.812-05:00&quot;,
      &quot;updated_at&quot;: &quot;2024-02-10T18:40:34.879-06:00&quot;,
      &quot;sort&quot;: &quot;ETHICS&quot;,
      &quot;alpha&quot;: &quot;E&quot;
    },
    {
      &quot;id&quot;: 943,
      &quot;name&quot;: &quot;Policy&quot;,
      &quot;created_at&quot;: &quot;2016-11-03T15:56:26.812-05:00&quot;,
      &quot;updated_at&quot;: &quot;2024-02-05T17:28:34.060-06:00&quot;,
      &quot;sort&quot;: &quot;POLICY&quot;,
      &quot;alpha&quot;: &quot;P&quot;
    }
  ],
  &quot;talent_attending&quot;: null,
  &quot;title_only&quot;: false,
  &quot;track_display_name&quot;: &quot;Tech &amp; AI track sponsored by IBM&quot;,
  &quot;trailer_id&quot;: null,
  &quot;trailer_url&quot;: null,
  &quot;video_on_demand&quot;: null,
  &quot;vimeo_id&quot;: null,
  &quot;vod&quot;: false,
  &quot;xr_project_type&quot;: null,
  &quot;youtube_id&quot;: null,
  &quot;related_sales_client&quot;: null
}</pre>
  </details>
</section></main>
  <footer class="site-footer">
    <p>Source code: <a href="https://github.com/max2697/SXSW-for-agents">GitHub repository</a></p>
  </footer>
  
</body>
</html>